{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0aStgWSO0E0E"
   },
   "source": [
    "# **Cherry Blossom Data Preparation and Exploration**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "1eLEkw5O0ECa"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "The objective of this notebook is to prepare the cherry blossom image dataset acquired from Kaggle (https://www.kaggle.com/datasets/codeinstitute/cherry-leaves) for further analysis and modeling. This includes data cleaning, preprocessing, and feature extraction tasks necessary to enhance the quality and usability of the dataset.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "Cherry blossom image dataset: A collection of images representing cherry leaves, including both healthy and powdery mildew-infected leaves.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "Processed dataset: A cleaned and transformed version of the cherry blossom image dataset, ready for analysis and modeling.\n",
    "Preprocessing code: Python code snippets and functions used for data cleaning, preprocessing, and feature extraction.\n",
    "Saved dataset file: A file containing the processed dataset in a suitable format for easy loading in subsequent notebooks or scripts.\n",
    "\n",
    "## Additional Comments\n",
    "\n",
    "The data preparation steps may include image resizing, normalization, noise removal, and other techniques to improve the quality and relevance of the cherry blossom image data. The notebook will focus on preparing the data for visualization, feature engineering, and model training stages of the project.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9uWZXH9LwoQg"
   },
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "cqP-UeN-z3i2"
   },
   "source": [
    "# Change working directory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "aOGIGS-uz3i2"
   },
   "source": [
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wZfF_j-Bz3i4",
    "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kuro/Desktop/PP5 Project/pp5-mildew-detection-in-cherry-leaves/jupyter_notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9MWW8E7lz3i7"
   },
   "source": [
    "We want to make the parent of the current directory the new current directory\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "TwHsQRWjz3i9",
    "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You set a new current directory\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "M_xPk_Ijz3i-"
   },
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vz3S-_kjz3jA",
    "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kuro/Desktop/PP5 Project/pp5-mildew-detection-in-cherry-leaves'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-mavJ8DibrcQ"
   },
   "source": [
    "# Installing Kaggle and importing the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section 1 content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.15.tar.gz (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in ./env/lib/python3.9/site-packages (from kaggle) (1.16.0)\n",
      "Collecting certifi (from kaggle)\n",
      "  Using cached certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
      "Requirement already satisfied: python-dateutil in ./env/lib/python3.9/site-packages (from kaggle) (2.8.2)\n",
      "Collecting requests (from kaggle)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting tqdm (from kaggle)\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Using cached python_slugify-8.0.1-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting urllib3 (from kaggle)\n",
      "  Using cached urllib3-2.0.3-py3-none-any.whl (123 kB)\n",
      "Requirement already satisfied: bleach in ./env/lib/python3.9/site-packages (from kaggle) (6.0.0)\n",
      "Requirement already satisfied: webencodings in ./env/lib/python3.9/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle)\n",
      "  Using cached text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->kaggle)\n",
      "  Downloading charset_normalizer-3.2.0-cp39-cp39-macosx_11_0_arm64.whl (124 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.9/site-packages (from requests->kaggle) (3.4)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.15-py3-none-any.whl size=99605 sha256=b2abe24a327865946492e3edb666c99268ede01812d4e648c9c204ebb3f00176\n",
      "  Stored in directory: /Users/kuro/Library/Caches/pip/wheels/2c/c2/6e/15b89ec0bbf983ac0ebbdf831640411513f19709817e40514f\n",
      "Successfully built kaggle\n",
      "Installing collected packages: text-unidecode, urllib3, tqdm, python-slugify, charset-normalizer, certifi, requests, kaggle\n",
      "Successfully installed certifi-2023.5.7 charset-normalizer-3.2.0 kaggle-1.5.15 python-slugify-8.0.1 requests-2.31.0 text-unidecode-1.3 tqdm-4.65.0 urllib3-2.0.3\n"
     ]
    }
   ],
   "source": [
    "# Install Kaggle\n",
    "!pip install kaggle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY3l0-AxO93d"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
    "! chmod 600 kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kuro/Desktop/PP5 Project/pp5-mildew-detection-in-cherry-leaves/env/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "Downloading cherry-leaves.zip to inputs/cherry-leaves-dataset\n",
      " 93%|███████████████████████████████████▏  | 51.0M/55.0M [00:02<00:00, 42.4MB/s]\n",
      "100%|██████████████████████████████████████| 55.0M/55.0M [00:02<00:00, 26.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "KaggleDataSetPath = \"codeinstitute/cherry-leaves\"\n",
    "DestinationFolder = \"inputs/cherry-leaves-dataset\"\n",
    "\n",
    "! kaggle datasets download -d {KaggleDataSetPath} -p {DestinationFolder}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(DestinationFolder + '/cherry-leaves.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(DestinationFolder)\n",
    "\n",
    "os.remove(DestinationFolder + '/cherry-leaves.zip')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_image_files(my_data_dir):\n",
    "    image_extensions = ('.png', '.jpg', '.jpeg')\n",
    "    folders = ['healthy', 'powdery_mildew']\n",
    "    \n",
    "    for folder in folders:\n",
    "        folder_path = os.path.join(my_data_dir, folder)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            files = os.listdir(folder_path)\n",
    "            num_image_files = 0\n",
    "            num_non_image_files = 0\n",
    "            \n",
    "            for file in files:\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                \n",
    "                if os.path.isfile(file_path):\n",
    "                    _, extension = os.path.splitext(file)\n",
    "                    if extension.lower() not in image_extensions:\n",
    "                        os.remove(file_path)  # Remove non-image file\n",
    "                        num_non_image_files += 1\n",
    "                    else:\n",
    "                        num_image_files += 1\n",
    "            \n",
    "            print(f\"Folder: {folder} - has image files: {num_image_files}\")\n",
    "            print(f\"Folder: {folder} - had non-image files: {num_non_image_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: healthy - has image files: 2104\n",
      "Folder: healthy - had non-image files: 0\n",
      "Folder: powdery_mildew - has image files: 2104\n",
      "Folder: powdery_mildew - had non-image files: 0\n"
     ]
    }
   ],
   "source": [
    "remove_non_image_files(my_data_dir='inputs/cherry-leaves-dataset/cherry-leaves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "\n",
    "def split_train_validation_test_images(my_data_dir, train_set_ratio, validation_set_ratio, test_set_ratio):\n",
    "    if train_set_ratio + validation_set_ratio + test_set_ratio != 1.0:\n",
    "        print(\"train_set_ratio + validation_set_ratio + test_set_ratio should sum to 1.0\")\n",
    "        return\n",
    "\n",
    "    labels = os.listdir(my_data_dir)\n",
    "    if 'cherry-leaves' in labels:\n",
    "        labels = os.listdir(os.path.join(my_data_dir, 'cherry-leaves'))\n",
    "\n",
    "    if 'test' in labels:\n",
    "        return\n",
    "\n",
    "    # Create necessary folders\n",
    "    os.makedirs(os.path.join(my_data_dir, 'cherry-leaves', 'train', 'healthy'))\n",
    "    os.makedirs(os.path.join(my_data_dir, 'cherry-leaves', 'train', 'powdery_mildew'))\n",
    "    os.makedirs(os.path.join(my_data_dir, 'cherry-leaves', 'validation', 'healthy'))\n",
    "    os.makedirs(os.path.join(my_data_dir, 'cherry-leaves', 'validation', 'powdery_mildew'))\n",
    "    os.makedirs(os.path.join(my_data_dir, 'cherry-leaves', 'test', 'healthy'))\n",
    "    os.makedirs(os.path.join(my_data_dir, 'cherry-leaves', 'test', 'powdery_mildew'))\n",
    "\n",
    "    for label in labels:\n",
    "        files = os.listdir(os.path.join(my_data_dir, 'cherry-leaves', label))\n",
    "        random.shuffle(files)\n",
    "\n",
    "        total_files = len(files)\n",
    "        train_set_size = int(total_files * train_set_ratio)\n",
    "        validation_set_size = int(total_files * validation_set_ratio)\n",
    "        test_set_size = total_files - train_set_size - validation_set_size\n",
    "\n",
    "        train_files = files[:train_set_size]\n",
    "        validation_files = files[train_set_size:train_set_size + validation_set_size]\n",
    "        test_files = files[train_set_size + validation_set_size:]\n",
    "\n",
    "        # Move files to the appropriate folders based on ratios\n",
    "        for file_name in train_files:\n",
    "            src_path = os.path.join(my_data_dir, 'cherry-leaves', label, file_name)\n",
    "            dest_path = os.path.join(my_data_dir, 'cherry-leaves', 'train', label, file_name)\n",
    "            shutil.move(src_path, dest_path)\n",
    "\n",
    "        for file_name in validation_files:\n",
    "            src_path = os.path.join(my_data_dir, 'cherry-leaves', label, file_name)\n",
    "            dest_path = os.path.join(my_data_dir, 'cherry-leaves', 'validation', label, file_name)\n",
    "            shutil.move(src_path, dest_path)\n",
    "\n",
    "        for file_name in test_files:\n",
    "            if label == 'healthy':\n",
    "                dest_folder = 'test/healthy'\n",
    "            else:\n",
    "                dest_folder = 'test/powdery_mildew'\n",
    "            src_path = os.path.join(my_data_dir, 'cherry-leaves', label, file_name)\n",
    "            dest_path = os.path.join(my_data_dir, 'cherry-leaves', dest_folder, file_name)\n",
    "            shutil.move(src_path, dest_path)\n",
    "\n",
    "        # Remove the label folder once files are moved\n",
    "        os.rmdir(os.path.join(my_data_dir, 'cherry-leaves', label))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The training set is divided into a 0.70 ratio of data.\n",
    "- The validation set is divided into a 0.10 ratio of data.\n",
    "- The test set is divided into a 0.20 ratio of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_data_dir = 'inputs/cherry-leaves-dataset/'\n",
    "\n",
    "train_set_ratio = 0.7\n",
    "validation_set_ratio = 0.1\n",
    "test_set_ratio = 0.2\n",
    "\n",
    "split_train_validation_test_images(my_data_dir, train_set_ratio, validation_set_ratio, test_set_ratio)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ltNetd085qHf"
   },
   "source": [
    "# Push files to Repo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aKlnIozA4eQO",
    "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    # create here your folder\n",
    "    # os.makedirs(name='')\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Data Practitioner Jupyter Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
